{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AstolfoMix E2E merger #\n",
    "\n",
    "Super rare N-to-1 SDXL merger with merging algorithms. ~~SDXL only.~~\n",
    "\n",
    "## Abstract ##\n",
    "\n",
    "- Base code: [Examples in sd-mecha](https://github.com/ljleb/sd-mecha/blob/main/examples)\n",
    "- Using [sd-mecha](https://github.com/ljleb/sd-mecha) as main library. **Thank you [@ljleb](https://github.com/ljleb/) for the codebase, [@illyaeater](https://github.com/Enferlain), and [@silveroxides](https://github.com/silveroxides) for the alpha tester.**\n",
    "- Each generated model will have its own model metadata and `*.mecha` ~~assembly like~~ [recipe](https://github.com/ljleb/sd-mecha/blob/main/examples/recipes/test_split_unet_text_encoder.mecha). Open it with text editor.\n",
    "- **No need to waste 1TB+ of disk space for pariwise merging and iterlate with WebUI.** However you should know the \"model pool\", otherwise it is likely result in a worse model. \n",
    "\n",
    "## Required libraries ##\n",
    "\n",
    "- `torch>=2.0.1`\n",
    "- `tensordict`\n",
    "- `sd-mecha` (I prefer [clone](https://github.com/6DammK9/sd-mecha/tree/main) the source code inplace,current version as on 241011, branch [della](https://github.com/6DammK9/sd-mecha/tree/della)), until [this PR](https://github.com/ljleb/sd-mecha/pull/41) has been merged.\n",
    "- [safetensors](https://huggingface.co/docs/safetensors/index)\n",
    "- [diffusers](https://huggingface.co/docs/diffusers/installation)\n",
    "- [pytorch](https://pytorch.org/get-started/locally/#windows-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported merging algorithms ##\n",
    "\n",
    "- `ALGO_DARE` as [DARE (ICML2024)](https://arxiv.org/abs/2311.03099) and [DELLA](https://arxiv.org/abs/2406.11617), \"TIES w/ DARE\", along with DROP only (no rescale)\n",
    "- `ALGO_TIES` as [TIES (NeurIPS2023)](https://arxiv.org/abs/2306.01708), along with [TIES-SOUP](https://github.com/6DammK9/nai-anime-pure-negative-prompt/blob/main/ch01/ties.md#spinoff-ties-soup) modified by me\n",
    "- `ALGO_AVERAGE` as [ModelSoup](https://arxiv.org/abs/2203.05482) as \"Averaging with filtered components\". Running average for merging pairwise. Slower but the most memory efficient. Can fit inside GPU.\n",
    "- `ALGO_NAVG` as [ModelSoup](https://arxiv.org/abs/2203.05482) as \"Averaging with filtered components\". Brutally merge all models at once.\n",
    "- `ALGO_MEDIAN`: part of [RFA (IEEE2022)](https://arxiv.org/abs/1912.13445), as \"Geometric Median\". Iterlative deterministic approach. Slow for algerba, fast for gradient descent.\n",
    "\n",
    "### Notes on MEDIAN ###\n",
    "\n",
    "- $O(N)$ for space complexity. See the table below for my actual running time / RAM usage *My WS became laggy because of high latency of [PMem (always overtemperature)](https://www.servethehome.com/intel-optane-dc-persistent-memory-guide-for-pmem-100-pmem-200-and-pmem-300-optane-dimms/)*.\n",
    "- $O(N log N)$ for time complexity, but more like $O(N)$ with high constant. It requries **40 hours** with limited 16 threads. Currently limited to single CPU. [Intel OpenMP hints on how to utilize many CPUs but I don't know how to operate.](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#intel-openmp-runtime-library-libiomp)\n",
    "- [Lists Comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp) is fast and efficient, but have large footprint in memory.\n",
    "- DELLA / DARE / TIES are all compatible with [Geometric Median](https://en.wikipedia.org/wiki/Geometric_median), meanwhile Weiszfeld's algorithm is already utilized which is $O(N)$ approximation.\n",
    "\n",
    "|Date|Algo|Model counts|Threads|RAM Usage (TB, FP64)|Time used (Hours, Xeon 8358 x2)|\n",
    "|---|---|---|---|---|---|\n",
    "|240607|TGMD|117|16|1.214|14|\n",
    "|240622|TGMD|133|8|< 1.0|12.5|\n",
    "|240830|TGMD|192|8|1.446|41.5|\n",
    "|241002|DGMLA|192|16|1.452|39.1|\n",
    "|241006|DGMLA|20|48|0.358|2.33|\n",
    "|241011|DGMLA|216|48|3.500|36.2|\n",
    "|250228|DGMLA|256|24|2.600|39.0|\n",
    "\n",
    "it takes **1.214TB of RAM** with limited 16 threads (116 models). \n",
    "\n",
    "### Notes on DELLA / DARE / TIES ###\n",
    "\n",
    "- After trying, I think filtering models are not useful. Therefore enable `MODE_RAW` only is good.\n",
    "- $O(N)$ of space complexity. For merging 102 SDXL models, it requires **410GB for TIES** and **450GB for DARE** (with limited 16 threads). Full 128 threads will OOM for 512GB system RAM.\n",
    "- $O(N)$ of time complexity also. For merging 102 SDXL models, it requires **75 minutes for TIES** and **105 minutes for DARE** (with limited 16 threads). Speedup will be low after 8 threads.\n",
    "- `sd-mecha` has already worked so hard on optimization, however `conditioner.embedders.1.model.token_embedding.weight` is a huge layer with `[49408, 1280]` in size. Merging this single layer took 390GB for 102 SDXL models. Unless there is inplace merge, this issue will limit the size of model pool.\n",
    "- DELLA is $O(NlogN)$ for sorting. From unit test it projects around 4-6x more time to merge.\n",
    "\n",
    "### Notes on NAVG / MODELSTOCK ###\n",
    "\n",
    "- Required time: 26 (RAW) for 116 models. May be useful if you don't have GPU, or you want minimal error (within FP64!) by using single merging step.\n",
    "- CPU usage: **100% with AVX2.**\n",
    "- RAM usage: **Around 241GB**. $O(N)$ of space complexity.\n",
    "\n",
    "### Notes on averaging with filtered models ###\n",
    "\n",
    "- Required time: 11 (RAW) + 70 * 3 * 1.66 (TE) + 67 (SELECTED_TE) + 70 * 2.83 (UNET) + 43.9 (FINAL) + 102.5 (E2E) minutes = **12.85 hours** for 70 models \n",
    "- CPU usage: **100% with AVX2.**\n",
    "- RAM usage: *Around 32GB*.\n",
    "- VRAM usage: *Around 4GB*. \n",
    "- Storage usage: $5N+3$ SDXL models, including $N$ raw models. For $N=70$, it will use **2.24TB** for the most efficient approach.\n",
    "- I intentionally make it into Python notebook because I need to switch mode this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model naming schema ##\n",
    "\n",
    "- `RAW` as `_x001`: Place all raw models. Will generate `x102a` as averaged model regardless components.\n",
    "- `CLIP` as `_x001te`: Will generate all models as `x102a` replaced with `_x001`'s TE. Will be a set of `te0`, `te1`, `te2`. Use these models for model selection. \n",
    "- `UNET` as `_x102a-x099te0x099te1`: *Require selected TEs.* Will generate all models as `_102`'s UNET and average of selected `te0` and `te1`. VAE will be `x25a`.\n",
    "- `FINAL` as `e2e`: Final model as `x102`.\n",
    "\n",
    "## Recommened directories to make ##\n",
    "\n",
    "- `raw`: Store the raw $N$ models\n",
    "- `clip`: Store $3N$ models for CLIP selection\n",
    "- `unet`: Store $N$ models for UNET selection\n",
    "\n",
    "## Operation Mode ##\n",
    "\n",
    "- [`RAW`, `CLIP`, `UNET`, `FINAL`]. Procedure will be *mutually exclusive*. I will keep restarting the whole notebook.\n",
    "\n",
    "## Limitation ##\n",
    "\n",
    "- ~~VAE remains unmanaged.~~ VAE can be picked from one of the raw models.\n",
    "- SDXL models only. I don't need this for SD1 and SD2.\n",
    "- Safetensors only. \n",
    "\n",
    "## WTF why and will it work? ##\n",
    "\n",
    "- Yes. [It is part of my research](./README_XL.md).\n",
    "- Image comparasion will be listed there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Pseudocode of sd-mecha ##\n",
    "\n",
    "- Note that the core concept is different from WebUI or supermerger. It focus on [serialization](https://www.geeksforgeeks.org/serialization-in-java/), along with *multiple merging methods* and *custom applied areas*.\n",
    "\n",
    "- It will pick `model_b_as_recipe` for every merge key and `model_a` for every passthroguh key\n",
    "\n",
    "- Sample code: `model_b_as_recipe = sd_mecha.merge_methods(model_a, model_b_as_recipe, alpha, beta, etc) #returns model_a`\n",
    "\n",
    "- For example, in `n_average`, `alpha` tends to `1`, instead of `0` in WebUI. \n",
    "\n",
    "- Also, `pick_vae` will show a special case on \"bake VAE\": `model_a_instead = sd_mecha.merge_methods(model_a, model_b_as_recipe, alpha=1) #returns model_a`\n",
    "\n",
    "Algorithm `SD-MECHA`:\n",
    "\n",
    "------\n",
    "\n",
    "- Let\n",
    "\n",
    "$\\{model_A, model_B\\, model_C\\} \\in models$ and $arch_{models} \\in arch_{SD}$ and is consistant (i.e. $arch_{model_A}=arch_{model_B}$)\n",
    "\n",
    "$\\{SumAverage,AddDiff,Rotate,ReBasin, etc.\\} \\in merge$\n",
    "\n",
    "$\\{CLIP, UNET, VAE\\} \\in models$, but $\\{CLIP, UNET\\} \\in \\alpha, \\{VAE\\} \\notin \\alpha$\n",
    "\n",
    "$ \\alpha = [0,1] , \\alpha=0 \\implies model_A, \\alpha=1 \\implies model_B$\n",
    "\n",
    "- Repeat:\n",
    "\n",
    "$model_A, model_B, merge, \\alpha, \\beta, etc. \\leftarrow deserialize(recipe)$ or user defined\n",
    "\n",
    "$model_A \\leftarrow merge(model_A, model_B, \\alpha, \\beta, etc.)$\n",
    "\n",
    "$model_B \\leftarrow model_A$\n",
    "\n",
    "$recipe \\leftarrow serialize(model_B)$\n",
    "\n",
    "- Until no more $model_B$\n",
    "\n",
    "- Return $recipe$\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Is dependency fufilled?\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0+cu124'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main module.\n",
    "import sd_mecha\n",
    "\n",
    "sd_mecha.set_log_level() #INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for OMP: Error #15\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input session starts here. ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify all the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_BASE = \"F:/NOVELAI/astolfo_mix/sdxl/\" #To set up merger\n",
    "\n",
    "DIR_RAW = \"raw/\" #To load N models\n",
    "DIR_CLIP = \"clip/\"  #To write 3N models\n",
    "DIR_UNET = \"unet/\" #To write N models\n",
    "DIR_FINAL = \"./\" #To write 1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check on directory and make the model name prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MECHA_RECIPE_EXT = \".mecha\"\n",
    "MECHA_MODEL_EXT = \".safetensors\"\n",
    "\n",
    "MODEL_LIST_RAW = os.listdir(\"{}{}\".format(DIR_BASE,DIR_RAW))\n",
    "# Exclude yaml.\n",
    "MODEL_LIST_RAW = list(filter(lambda p: p.endswith(MECHA_MODEL_EXT), MODEL_LIST_RAW)) #p.endswith(\".ckpt\") or p.endswith(\".safetensors\") or p.endswith(\".bin\")\n",
    "if len(MODEL_LIST_RAW) < 2:\n",
    "    raise Exception(\"Need at least 2 models for merge.\")\n",
    "#model_list = list(map(lambda p: os.path.splitext(os.path.basename(p))[0], model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 raw models found.\n"
     ]
    }
   ],
   "source": [
    "print(\"{} raw models found.\".format(len(MODEL_LIST_RAW)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model selection. Index start with 1. Check model list for ordering! *If you are using merging algorithms, you can ignore the list.*\n",
    "```log\n",
    "te0: --,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--=0\n",
    "te1: 02,--,04,07,09,--,--,15,--,--,--,--,30,--,37,39,40,46,47,49,54,55,57,59,60,61,63,67,68,69,70,71=-24\n",
    "te2: 02,--,04,07,--,--,--,15,--,--,--,--,--,31,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--=-5\n",
    "=sd: --,03,--,--,--,10,12,--,16,18,19,25,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--=-7\n",
    "\n",
    "te0: =0\n",
    "te1: 01,03,09,10,12,14,15,16,18,19,25,29,31,34,40,44,47,48,49,50,53,56,58,60,61,64,65,66=-28\n",
    "unet: 02,03,05,14,16,18,19,24,28,29,34,39,41,44,45,47,48,50,51,52,53,55,56,58,60,61,64,65,66,67,71,72,73=-33\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 241006: Cleared since I am not going to use them anymore.\n",
    "MODEL_SELECTION_TE0 = [i+1 for i in range(len(MODEL_LIST_RAW)) if i+1 not in []] \n",
    "MODEL_SELECTION_TE1 = [i+1 for i in range(len(MODEL_LIST_RAW)) if i+1 not in []] \n",
    "MODEL_SELECTION_UNET = [i+1 for i in range(len(MODEL_LIST_RAW)) if i+1 not in []]\n",
    "\n",
    "#001 is the Original SDXL\n",
    "MODEL_SELECTION_OG = 1\n",
    "#002 has the \"FP16 fixed VAE\"\n",
    "MODEL_SELECTION_VAE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE0:256,TE1:256,UNET:256\n"
     ]
    }
   ],
   "source": [
    "print(\"TE0:{},TE1:{},UNET:{}\".format(len(MODEL_SELECTION_TE0),len(MODEL_SELECTION_TE1),len(MODEL_SELECTION_UNET)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify all the keywords (I'll avoid hardcode because they will be everywhere)\n",
    "\n",
    "Note that I only run 1 merging algorithm at a time, otherwise my code will explode (too many items to consider)\n",
    "\n",
    "Merging algorithms usually using all models i.e. `MODE_RAW` only. Others are dedicated for `ALGO_AVERAGE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE_RAW = 'MODE_RAW'\n",
    "MODE_CLIP = 'MODE_CLIP'\n",
    "MODE_UNET = 'MODE_UNET'\n",
    "MODE_FINAL = 'MODE_FINAL'\n",
    "ALGO_AVERAGE = 'ALGO_AVERAGE' #Uniform Soup in Model Soup (implied), running average\n",
    "ALGO_NAVG = 'ALGO_NAVG' #Uniform Soup in Model Soup (implied), single shot\n",
    "ALGO_TIES = 'ALGO_TIES' #TIES merge (Algo 1)\n",
    "ALGO_DARE = 'ALGO_DARE' #TIES w/ DARE\n",
    "ALGO_MODELSTOCK = 'ALGO_MODELSTOCK' #ModelStock (mergekit approach)\n",
    "ALGO_MEDIAN = 'ALGO_MEDIAN' #Geometric Median\n",
    "\n",
    "ALGO_ACTIVATED = ALGO_DARE #ALGO_AVERAGE, ALGO_NAVG, ALGO_TIES, ALGO_DARE, ALGO_MODELSTOCK, ALGO_MEDIAN\n",
    "MODE_ACTIVATED = [MODE_RAW] #[MODE_RAW,MODE_CLIP,MODE_UNET,MODE_FINAL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generations of AstolfoMix, I am tired to delete 600x unused files. Therefore I am going to skip the recipe generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_GEN_MANUAL_FILTER = (MODE_ACTIVATED == [MODE_RAW])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since AstolfoMix is a huge mix, and oppose to introduce too many hypermeters. \n",
    "- Optimization is pain, see [AutoMBW-rt](https://github.com/6DammK9/auto-MBW-rt) which involves 27 parameters and a set of testing prompts.\n",
    "- Therefore I suggest not to adjust any numbers until you have your \"baseline model\" generated. Note that \"averaging\" is parameterless. \n",
    "- Since the $\\lambda$ kicks in as `add_diff`, we can use seperated script to make models with different $\\lambda$, so no need to rerun this script which is time consuming.\n",
    "- Instead, we rerun the script for a *picked* $\\lambda$. $k$ is being obvious to be 1.0 because 0.2 is not good.\n",
    "- DARE add $p$ to the equation, which make things complicated. Currently there is no discussion how it behaves, we only know it improves performance under some task (however I have no specific task here).\n",
    "- Model Stock propose an idea to \"drag mean to center (median?)\". However `mergekit`'s approach is \"mean of cosine similarity\" due to the difficulty of the N model case. It can be applied to TIES as `apply_stock` since $\\tau_m$ is an average (mean) of filtered weight. $\\epsilon$ is considered for implementation only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is old merging log.\n",
    "\n",
    "- DARE-TIES-SOUP: `24050903`. Best result from previous iterlation. `p=0.1,k=1.0,alpha=0.9,vote_sgn=1.0`\n",
    "- NAVG: `24060301`. Control Test.\n",
    "- MODELSTOCK: `24060302`. Failed with `nan` error. `cos_eps=1e-6`\n",
    "- MEDIAN: `24060303`. Param sticked with source. `eps=1e-6,maxiter=100,ftol=1e-20`\n",
    "- DARE-TIES-STOCK: `24060701`. Looks like STOCK has did nothing. `p=0.1,k=1.0,alpha=0.9,vote_sgn=1.0,apply_stock=1.0,cos_eps=1e-6`\n",
    "- DARE-TIES-GM: `24060702`. Suprisingly looks like MEDIAN. `p=0.1,k=1.0,alpha=0.9,vote_sgn=1.0,apply_median=1.0,eps=1e-6,maxiter=100,ftol=1e-20`\n",
    "- DARE-TIES-GM: `24062201`. Bumped from 116 to 133 models. Same as `24060702`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the *recent* merging log.\n",
    "- DGMLA: `24100201`. 192 models. `p=0.1,eps=-0.05`. Baseline.\n",
    "- DGMLA: `24100601`. 20 models. `p=0.1,eps=-0.05`. Still works.\n",
    "- DGMLA: `24100602`. 20 models. `p=0.3,eps=-0.30`. Doesn't work.\n",
    "- DGMLA: `24100603`. 20 models. `p=0.1,eps=0.05`. Works in a different way.\n",
    "- DGMLA: `24100604`. 20 models. `p=0.1,eps=-0.1`. Works in the same way.\n",
    "- DGMLA: `24101101`. 216 models. `p=0.1,eps=-0.1`. Works as expected.\n",
    "- DGMLA: `25022801`. 256 models. `p=0.1,eps=-0.1`. **Kinda works, but image so abstract. Need more study.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DARE_PROB = 0.1 #By my experience. Paper has no recommended value, but code default at 0.1\n",
    "DELLA_EPS = -0.1 #By my experience. Paper has no recommended value, but code default at 0.07 with p=0.35\n",
    "DARE_DROP = 0.0 #1.0 for full DARE, 0.0 for Dropout only \n",
    "TIES_TOP_K = 1.0 #From ljleb, verified by me, must be 1.0, even paper suggest 0.2 as \"Top 20%\"\n",
    "TIES_VOTE_SGN = 1.0 #0.0 for plain TIES, > 0.0 for TIES-SOUP\n",
    "TIES_LAMBDA = 1.0 #1.0 From ljleb and paper, use other script to split in to different lamba\n",
    "TIES_MODELSTOCK = 0.0 #1.0 for applying \"t\" to voted weight (kind of average)\n",
    "TIES_MEDIAN = 1.0 #1.0 for applying geometric median instead of arithmetic mean in the last step.\n",
    "MODELSTOCK_EPS = 1e-6 #As torch's default.\n",
    "MEDIAN_EPS = 1e-6 #As torch's default.\n",
    "MEDIAN_MAXITER = 100 #As author\n",
    "MEDIAN_FTOL = 1e-20 #As author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert version number, and the... *\"AstolfoMix\"*.\n",
    "\n",
    "If you want to make multiple versions of AstolfoMix with different algorithms, I suggest modify the `MODEL_NAME_KEYWORD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_SUFFIX = \"25022801-1458190\" #yymmddxx-commit\n",
    "MODEL_NAME_KEYWORD = \"AstolfoMix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change if your PC is in trouble.\n",
    "\n",
    "My WS: [Xeon 8358 ES, X12DPI-N6, 4TB DDR4 w/ PMem, 2x RTX2080ti 22G, P4510 4TB *2](https://github.com/6DammK9/nai-anime-pure-negative-prompt/blob/main/ch04/ice_lake_ws.md). ~~Overkill~~ Suitable for a merger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_seed = 250228 #For reproducible result\n",
    "g_device = \"cuda:1\" if ALGO_ACTIVATED == ALGO_AVERAGE else \"cpu\"  #I have 2 GPUS and this is the CPU slot\n",
    "g_precision_while_merge = torch.float64 if \"cuda\" in g_device else torch.float64 #I have RAM\n",
    "g_precision_final_model = torch.float16 if \"cuda\" in g_device else torch.float16 #fp16\n",
    "\n",
    "#240407: 2**34 will throw NaN issue. Stay with default = 2**28\n",
    "g_total_buffer_size=2**28\n",
    "#240507: (Not effective) DARE requires single thread to prevent OOM\n",
    "#240603: I have my machine upgraded. And... OS becomes unstable.\n",
    "g_threads = 24 #16 if ALGO_ACTIVATED == ALGO_DARE else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input shuold ends here. ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output model name. I want to keep the format, however I need to manage the name manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT_BYPASS = \"{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto zfill under total model count\n",
    "def az(n):\n",
    "    return str(n).zfill(math.ceil(math.log10(len(MODEL_LIST_RAW))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLIP = (\"te0\",\"te1\",\"te2\")\n",
    "N_RAW = \"_x{}\"\n",
    "N_ITR = \"{}a\"\n",
    "N_PICKED = \"x{}\"\n",
    "\n",
    "MODEL_NAME_RAW_PREFIX = (N_ITR.format(N_PICKED)).format(az(len(MODEL_LIST_RAW)-1)) #x102a\n",
    "\n",
    "MODEL_NAME_TE = (\"{}{}{}{}\".format(N_PICKED,N_CLIP[0],N_PICKED,N_CLIP[1])).format(az(len(MODEL_SELECTION_TE0)-1),az(len(MODEL_SELECTION_TE1)-1)) #x102te0x102te1\n",
    "MODEL_NAME_FINAL_PREFIX = N_PICKED.format(az(len(MODEL_SELECTION_UNET)-1)) #x102\n",
    "\n",
    "MODEL_NAME_RAW = \"{}-{}-{}\".format(MODEL_NAME_RAW_PREFIX,MODEL_NAME_KEYWORD,MODEL_NAME_SUFFIX) #x102a-AstolfoMix-e2e-240507-4edc67c\n",
    "MODEL_NAME_TE_ITR = \"{}-{}-{}{}-{}\".format(MODEL_NAME_RAW_PREFIX,MODEL_NAME_KEYWORD,FORMAT_BYPASS,FORMAT_BYPASS,MODEL_NAME_SUFFIX) #x102a-AstolfoMix-_x102te0-e2e-240507-4edc67c\n",
    "MODEL_NAME_SELECTED_TE = \"{}-{}-{}-{}\".format(MODEL_NAME_RAW_PREFIX,MODEL_NAME_KEYWORD,MODEL_NAME_TE,MODEL_NAME_SUFFIX) #x102a-AstolfoMix-x102te0x102te1-e2e-240507-4edc67c\n",
    "MODEL_NAME_UNET_ITR = \"_{}-{}-{}-{}\".format(FORMAT_BYPASS,MODEL_NAME_KEYWORD,MODEL_NAME_TE,MODEL_NAME_SUFFIX) #_x102a-AstolfoMix-x102te0x102te1-e2e-240507-4edc67c\n",
    "MODEL_NAME_FINAL = \"{}-{}-{}-{}\".format(MODEL_NAME_FINAL_PREFIX,MODEL_NAME_KEYWORD,MODEL_NAME_TE,MODEL_NAME_SUFFIX) #x102-AstolfoMix-x102te0x102te1-e2e-240507-4edc67c\n",
    "MODEL_NAME_E2E = \"{}-{}-{}-e2e-{}\".format(MODEL_NAME_FINAL_PREFIX,MODEL_NAME_KEYWORD,MODEL_NAME_TE,MODEL_NAME_SUFFIX) #x102-AstolfoMix-x102te0x102te1-e2e-240507-4edc67c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive average model:                     x255a-AstolfoMix-25022801-1458190\n",
      "CLIP models to iterlate:                 x255a-AstolfoMix-{}{}-25022801-1458190\n",
      "Naive average model with selected CLIP:  x255a-AstolfoMix-x255te0x255te1-25022801-1458190\n",
      "UNET models to iterlate:                 _{}-AstolfoMix-x255te0x255te1-25022801-1458190\n",
      "Final merged model (staged):             x255-AstolfoMix-x255te0x255te1-25022801-1458190\n",
      "Final merged model (e2e):                x255-AstolfoMix-x255te0x255te1-e2e-25022801-1458190\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive average model:                     {}\".format(MODEL_NAME_RAW))\n",
    "print(\"CLIP models to iterlate:                 {}\".format(MODEL_NAME_TE_ITR))\n",
    "print(\"Naive average model with selected CLIP:  {}\".format(MODEL_NAME_SELECTED_TE))\n",
    "print(\"UNET models to iterlate:                 {}\".format(MODEL_NAME_UNET_ITR))\n",
    "print(\"Final merged model (staged):             {}\".format(MODEL_NAME_FINAL))\n",
    "print(\"Final merged model (e2e):                {}\".format(MODEL_NAME_E2E))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up merge receipe and merge scheduler ##\n",
    "\n",
    "- I'm still a bit panic about hardcoding. Getter / Setter will be fine. ~~No, you won't see OOP in python notebook.~~\n",
    "- Will always run. `MODE_ACTIVATED` controls actual merge process only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmk_raw():\n",
    "    return 'RAW'\n",
    "def rmk_ste():\n",
    "    return 'SELECTED_TE'\n",
    "def rmk_f():\n",
    "    return 'FINAL'\n",
    "def rmk_e2e():\n",
    "    return 'E2E'\n",
    "def rmk_te(i,j):\n",
    "    return 'CLIP{}_TE{}'.format(i,j) #CLIP1TE0\n",
    "def rmk_unet(i):\n",
    "    return 'UNET{}'.format(i)  #UNET1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_mapping = {}\n",
    "\n",
    "def set_rmk(k, v):\n",
    "    recipe_mapping[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_rm():\n",
    "    set_rmk(rmk_raw(), None)\n",
    "    set_rmk(rmk_ste(), None)\n",
    "    set_rmk(rmk_f(), None)\n",
    "\n",
    "    for i in range(len(MODEL_LIST_RAW)):\n",
    "        set_rmk(rmk_unet(i+1), None)\n",
    "        for j in range(3):\n",
    "            set_rmk(rmk_te(i+1,j), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_rm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single merger should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = sd_mecha.RecipeMerger(\n",
    "    models_dir=DIR_BASE,\n",
    "    default_device=g_device,\n",
    "    default_dtype=g_precision_while_merge,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define recipe extension, and make the model output path (Note that it is still being formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OS_MODEL_PATH_RAW = \"{}{}{}\".format(DIR_BASE,MODEL_NAME_RAW,MECHA_MODEL_EXT)\n",
    "RECIPE_PATH_RAW = \"{}{}{}\".format(DIR_BASE,MODEL_NAME_RAW,MECHA_RECIPE_EXT)\n",
    "MECHA_MODEL_PATH_RAW = \"{}{}\".format(DIR_FINAL,MODEL_NAME_RAW)\n",
    "\n",
    "OS_MODEL_PATH_TE_ITR = \"{}{}{}{}\".format(DIR_BASE,DIR_CLIP,MODEL_NAME_TE_ITR,MECHA_MODEL_EXT)\n",
    "RECIPE_PATH_TE_ITR = \"{}{}{}{}\".format(DIR_BASE,DIR_CLIP,MODEL_NAME_TE_ITR,MECHA_RECIPE_EXT)\n",
    "MECHA_MODEL_PATH_TE_ITR =  \"{}{}{}\".format(DIR_FINAL,DIR_CLIP,MODEL_NAME_TE_ITR)\n",
    "\n",
    "OS_MODEL_PATH_SELECTED_TE = \"{}{}{}\".format(DIR_BASE,MODEL_NAME_SELECTED_TE,MECHA_MODEL_EXT)\n",
    "RECIPE_PATH_SELECTED_TE = \"{}{}{}\".format(DIR_BASE,MODEL_NAME_SELECTED_TE,MECHA_RECIPE_EXT)\n",
    "MECHA_MODEL_PATH_SELECTED_TE =  \"{}{}\".format(DIR_FINAL,MODEL_NAME_SELECTED_TE)\n",
    "\n",
    "OS_MODEL_PATH_UNET_ITR = \"{}{}{}{}\".format(DIR_BASE,DIR_UNET,MODEL_NAME_UNET_ITR,MECHA_MODEL_EXT)\n",
    "RECIPE_PATH_UNET_ITR = \"{}{}{}{}\".format(DIR_BASE,DIR_UNET,MODEL_NAME_UNET_ITR,MECHA_RECIPE_EXT)\n",
    "MECHA_MODEL_PATH_UNET_ITR =  \"{}{}{}\".format(DIR_FINAL,DIR_UNET,MODEL_NAME_UNET_ITR)\n",
    "\n",
    "OS_MODEL_PATH_FINAL = \"{}{}{}\".format(DIR_BASE,MODEL_NAME_FINAL,MECHA_MODEL_EXT)\n",
    "RECIPE_PATH_FINAL = \"{}{}{}\".format(DIR_BASE,MODEL_NAME_FINAL,MECHA_RECIPE_EXT)\n",
    "MECHA_MODEL_PATH_FINAL = \"{}{}\".format(DIR_FINAL,MODEL_NAME_FINAL)\n",
    "\n",
    "OS_MODEL_PATH_E2E = \"{}{}{}\".format(DIR_BASE,MODEL_NAME_E2E,MECHA_MODEL_EXT)\n",
    "RECIPE_PATH_E2E = \"{}{}{}\".format(DIR_BASE,MODEL_NAME_E2E,MECHA_RECIPE_EXT)\n",
    "MECHA_MODEL_PATH_E2E = \"{}{}\".format(DIR_FINAL,MODEL_NAME_E2E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better test the ugly full file path\n",
    "def get_te_itr_path(s: str,i: int,j: int):\n",
    "    return s.format(N_RAW.format(az(i+1)),N_CLIP[j])\n",
    "\n",
    "def get_unet_itr_path(s: str,i: int):\n",
    "    return s.format((N_ITR.format(N_PICKED)).format(az(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample TE_ITR recipe path:   F:/NOVELAI/astolfo_mix/sdxl/clip/x255a-AstolfoMix-_x002te1-25022801-1458190.mecha\n",
      "Sample TE_ITR model path:    F:/NOVELAI/astolfo_mix/sdxl/clip/x255a-AstolfoMix-_x002te1-25022801-1458190.safetensors\n",
      "Sample UNET_ITR recipe path: F:/NOVELAI/astolfo_mix/sdxl/unet/_x002a-AstolfoMix-x255te0x255te1-25022801-1458190.mecha\n",
      "Sample UNET_ITR model path:  F:/NOVELAI/astolfo_mix/sdxl/unet/_x002a-AstolfoMix-x255te0x255te1-25022801-1458190.safetensors\n",
      "Does RAW model exists:       False\n",
      "Final model path:            ./x255-AstolfoMix-x255te0x255te1-25022801-1458190\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample TE_ITR recipe path:   {}\".format(get_te_itr_path(RECIPE_PATH_TE_ITR, 1, 1)))\n",
    "print(\"Sample TE_ITR model path:    {}\".format(get_te_itr_path(OS_MODEL_PATH_TE_ITR, 1, 1)))\n",
    "print(\"Sample UNET_ITR recipe path: {}\".format(get_unet_itr_path(RECIPE_PATH_UNET_ITR, 1)))\n",
    "print(\"Sample UNET_ITR model path:  {}\".format(get_unet_itr_path(OS_MODEL_PATH_UNET_ITR, 1)))\n",
    "print(\"Does RAW model exists:       {}\".format(os.path.isfile(OS_MODEL_PATH_RAW)))\n",
    "print(\"Final model path:            {}\".format(MECHA_MODEL_PATH_FINAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right before the merging stuffs, I need to clear some hardcode. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MECHA_IS_SDXL = \"sdxl\"\n",
    "MECHA_TXT1_IS_VITG = \"txt\"\n",
    "MECHA_TXT2_IS_VITL = \"txt2\"\n",
    "MECHA_UNET_IS_UNET = \"unet\"\n",
    "\n",
    "# 240407: Seems that safe to be float\n",
    "TAKE_MODEL_A = 0.0\n",
    "TAKE_MODEL_B = 1.0\n",
    "\n",
    "# 240407: New syntax proposed by ljleb\n",
    "TE0_ALPHA = (sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT1_IS_VITG], TAKE_MODEL_A) | sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT2_IS_VITL, MECHA_UNET_IS_UNET], TAKE_MODEL_B))\n",
    "TE1_ALPHA = (sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT2_IS_VITL], TAKE_MODEL_A) | sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT1_IS_VITG, MECHA_UNET_IS_UNET], TAKE_MODEL_B))\n",
    "TE2_ALPHA = (sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT1_IS_VITG, MECHA_TXT2_IS_VITL], TAKE_MODEL_A) | sd_mecha.default(MECHA_IS_SDXL, [MECHA_UNET_IS_UNET], TAKE_MODEL_B))\n",
    "TE0_ALPHA_INVERTED = (sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT2_IS_VITL, MECHA_UNET_IS_UNET], TAKE_MODEL_A) | sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT1_IS_VITG], TAKE_MODEL_B))\n",
    "TE1_ALPHA_INVERTED = (sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT1_IS_VITG, MECHA_UNET_IS_UNET], TAKE_MODEL_A) | sd_mecha.default(MECHA_IS_SDXL, [MECHA_TXT2_IS_VITL], TAKE_MODEL_B))\n",
    "\n",
    "CASTED_VAE_MODEL = sd_mecha.model(\"{}{}\".format(DIR_RAW,MODEL_LIST_RAW[MODEL_SELECTION_VAE - 1]), MECHA_IS_SDXL)\n",
    "CASTED_OG_MODEL = sd_mecha.model(\"{}{}\".format(DIR_RAW,MODEL_LIST_RAW[MODEL_SELECTION_OG - 1]), MECHA_IS_SDXL)\n",
    "\n",
    "FALLBACK_AS_OG_MODEL = CASTED_OG_MODEL\n",
    "\n",
    "# 240603: Yes my algorithms are stackable. \"TSD Merge\" will have tons of parameters.\n",
    "KWARGS_NAVG = { 'dtype': g_precision_while_merge, 'device': g_device }\n",
    "KWARGS_MODELSTOCK = { 'cos_eps': MODELSTOCK_EPS, **KWARGS_NAVG }\n",
    "KWARGS_MEDIAN = { 'eps': MEDIAN_EPS, 'maxiter': MEDIAN_MAXITER, 'ftol': MEDIAN_FTOL, **KWARGS_NAVG }\n",
    "KWARGS_TIES = { 'alpha': TIES_LAMBDA, 'k': TIES_TOP_K, 'vote_sgn': TIES_VOTE_SGN, 'apply_stock': TIES_MODELSTOCK, 'apply_median': TIES_MEDIAN, **KWARGS_MODELSTOCK, **KWARGS_MEDIAN }\n",
    "KWARGS_DARE = { 'probability': DARE_PROB, 'della_eps': DELLA_EPS, 'rescale': DARE_DROP, 'seed': g_seed, **KWARGS_TIES }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick VAE ###\n",
    "- It will pick `cur_model` for every merge key and `vae_model` for every passthroguh key\n",
    "- Note that `cur_model` is already casted as `sd_mecha.model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_vae(cur_model):\n",
    "    return sd_mecha.weighted_sum(CASTED_VAE_MODEL, cur_model, alpha=TAKE_MODEL_B, dtype=g_precision_while_merge, device=g_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Average ###\n",
    "\n",
    "- Pay attention to the `alpha`. It is opposite to A1111: It is \"A merge to B\" instead of \"Merge A with B\".\n",
    "- Also the receipe is set of `RecipeNode` under [tree structure](https://en.wikipedia.org/wiki/Tree_(data_structure)). Therefore you can expect there are quite a lot of recursive stuffs (returning iteself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recipe_naive_merge():\n",
    "    models = list(map(lambda p: \"{}{}\".format(DIR_RAW,p),MODEL_LIST_RAW))\n",
    "\n",
    "    if ALGO_ACTIVATED == ALGO_AVERAGE:\n",
    "        recipe = models[0]\n",
    "        casted_recipe = sd_mecha.model(recipe, MECHA_IS_SDXL)\n",
    "        for i, model in enumerate(models[1:], start=2):\n",
    "            casted_model = sd_mecha.model(model, MECHA_IS_SDXL)\n",
    "            casted_recipe = sd_mecha.weighted_sum(casted_model, casted_recipe, alpha=(i-1)/i, dtype=g_precision_while_merge, device=g_device)\n",
    "    elif ALGO_ACTIVATED == ALGO_NAVG:\n",
    "        casted_models = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models]\n",
    "        casted_recipe = sd_mecha.n_average(*casted_models, **KWARGS_NAVG)        \n",
    "    elif ALGO_ACTIVATED == ALGO_MEDIAN:\n",
    "        casted_models = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models]\n",
    "        casted_recipe = sd_mecha.geom_median(*casted_models, **KWARGS_MEDIAN)     \n",
    "    elif ALGO_ACTIVATED == ALGO_MODELSTOCK:\n",
    "        casted_models = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models]\n",
    "        casted_recipe = sd_mecha.model_stock_n_models(CASTED_OG_MODEL, *casted_models, **KWARGS_MODELSTOCK)\n",
    "    elif ALGO_ACTIVATED == ALGO_TIES:\n",
    "        casted_models = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models]\n",
    "        casted_recipe = sd_mecha.add_difference_ties(CASTED_OG_MODEL, *casted_models, **KWARGS_TIES)\n",
    "    elif ALGO_ACTIVATED == ALGO_DARE:\n",
    "        casted_models = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models]\n",
    "        casted_recipe = sd_mecha.ties_with_dare(CASTED_OG_MODEL, *casted_models, **KWARGS_DARE)\n",
    "    else:\n",
    "        raise Exception(\"Algorithm {} is not supported.\".format(ALGO_ACTIVATED))\n",
    "    \n",
    "    return pick_vae(casted_recipe)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Saving recipe to F:\\NOVELAI\\astolfo_mix\\sdxl\\x255a-AstolfoMix-25022801-1458190.mecha\n"
     ]
    }
   ],
   "source": [
    "set_rmk(rmk_raw(), make_recipe_naive_merge())\n",
    "sd_mecha.serialize_and_save(recipe_mapping[rmk_raw()], RECIPE_PATH_RAW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Models to test ###\n",
    "- Note that `alpha` is using a special operator `|` which is \"Bitwise OR\".\n",
    "- Also recall \"TE0 use ViT-G / `txt1`\" and \"TE1 use ViT-L / `txt2`\" and \"TE2 use both\"\n",
    "- *I don't like the new syntax.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recipe_te_itr(p):\n",
    "    clip_model = \"{}{}\".format(DIR_RAW, p)\n",
    "    unet_model = \"{}{}\".format(MECHA_MODEL_PATH_RAW, MECHA_MODEL_EXT)\n",
    "    casted_clip_model = sd_mecha.model(clip_model, MECHA_IS_SDXL)\n",
    "    casted_unet_model = sd_mecha.model(unet_model, MECHA_IS_SDXL)\n",
    "    recipe_te0 = sd_mecha.weighted_sum(casted_clip_model, casted_unet_model, alpha=TE0_ALPHA, dtype=g_precision_while_merge, device=g_device)\n",
    "    recipe_te1 = sd_mecha.weighted_sum(casted_clip_model, casted_unet_model, alpha=TE1_ALPHA, dtype=g_precision_while_merge, device=g_device)\n",
    "    recipe_te2 = sd_mecha.weighted_sum(casted_clip_model, casted_unet_model, alpha=TE2_ALPHA, dtype=g_precision_while_merge, device=g_device)\n",
    "    return (pick_vae(recipe_te0), pick_vae(recipe_te1), pick_vae(recipe_te2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped generating unused recipes.\n"
     ]
    }
   ],
   "source": [
    "# 3N models\n",
    "if SKIP_GEN_MANUAL_FILTER:\n",
    "    print(\"Skipped generating unused recipes.\")\n",
    "else:\n",
    "    for i in range(len(MODEL_LIST_RAW)):\n",
    "        rte = make_recipe_te_itr(MODEL_LIST_RAW[i])\n",
    "        for j in range(len(N_CLIP)):    \n",
    "            set_rmk(rmk_te(i+1,j), rte[j])\n",
    "            sd_mecha.serialize_and_save(recipe_mapping[rmk_te(i+1,j)], get_te_itr_path(RECIPE_PATH_TE_ITR,i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picked CLIP Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recipe_ste():\n",
    "    raw_models = list(map(lambda p: \"{}{}\".format(DIR_RAW,p),MODEL_LIST_RAW))\n",
    "    models_te0 = [raw_models[i-1] for i in MODEL_SELECTION_TE0]\n",
    "    models_te1 = [raw_models[i-1] for i in MODEL_SELECTION_TE1]\n",
    "\n",
    "    unet_model = \"{}{}\".format(MECHA_MODEL_PATH_RAW, MECHA_MODEL_EXT)\n",
    "    casted_unet_model = sd_mecha.model(unet_model, MECHA_IS_SDXL)\n",
    "\n",
    "    if ALGO_ACTIVATED == ALGO_AVERAGE:\n",
    "        recipe_te0 = models_te0[0]\n",
    "        casted_recipe_te0 = sd_mecha.model(recipe_te0, MECHA_IS_SDXL)\n",
    "        for i, model in enumerate(models_te0[1:], start=2):\n",
    "            casted_model = sd_mecha.model(model, MECHA_IS_SDXL)\n",
    "            casted_recipe_te0 = sd_mecha.weighted_sum(casted_model, casted_recipe_te0, alpha=(i-1)/i, dtype=g_precision_while_merge, device=g_device)\n",
    "        \n",
    "        recipe_te1 = models_te1[0]\n",
    "        casted_recipe_te1 = sd_mecha.model(recipe_te1, MECHA_IS_SDXL)\n",
    "        for i, model in enumerate(models_te1[1:], start=2):\n",
    "            casted_model = sd_mecha.model(model, MECHA_IS_SDXL)\n",
    "            casted_recipe_te1 = sd_mecha.weighted_sum(casted_model, casted_recipe_te1, alpha=(i-1)/i, dtype=g_precision_while_merge, device=g_device)\n",
    "    elif ALGO_ACTIVATED == ALGO_NAVG:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.n_average(*casted_models_te0, **KWARGS_NAVG)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.n_average(*casted_models_te1, **KWARGS_NAVG)\n",
    "    elif ALGO_ACTIVATED == ALGO_MEDIAN:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.geom_median(*casted_models_te0, **KWARGS_MEDIAN)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.geom_median(*casted_models_te1, **KWARGS_MEDIAN)\n",
    "    elif ALGO_ACTIVATED == ALGO_MODELSTOCK:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.model_stock_n_models(CASTED_OG_MODEL, *casted_models_te0, **KWARGS_MODELSTOCK)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.model_stock_n_models(CASTED_OG_MODEL, *casted_models_te1, **KWARGS_MODELSTOCK)\n",
    "    elif ALGO_ACTIVATED == ALGO_TIES:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.add_difference_ties(CASTED_OG_MODEL, *casted_models_te0, **KWARGS_TIES)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.add_difference_ties(CASTED_OG_MODEL, *casted_models_te1, **KWARGS_TIES)\n",
    "    elif ALGO_ACTIVATED == ALGO_DARE:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.ties_with_dare(CASTED_OG_MODEL, *casted_models_te0, **KWARGS_DARE)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.ties_with_dare(CASTED_OG_MODEL, *casted_models_te1, **KWARGS_DARE)\n",
    "    else:\n",
    "        raise Exception(\"Algorithm {} is not supported.\".format(ALGO_ACTIVATED))  \n",
    "\n",
    "    casted_unet_model = sd_mecha.weighted_sum(casted_recipe_te0, casted_unet_model, alpha=TE0_ALPHA, dtype=g_precision_while_merge, device=g_device)\n",
    "    casted_unet_model = sd_mecha.weighted_sum(casted_recipe_te1, casted_unet_model, alpha=TE1_ALPHA, dtype=g_precision_while_merge, device=g_device)\n",
    "\n",
    "    return pick_vae(casted_unet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped generating unused recipes.\n"
     ]
    }
   ],
   "source": [
    "if SKIP_GEN_MANUAL_FILTER:\n",
    "    print(\"Skipped generating unused recipes.\")\n",
    "else:\n",
    "    set_rmk(rmk_ste(), make_recipe_ste())\n",
    "    sd_mecha.serialize_and_save(recipe_mapping[rmk_ste()], RECIPE_PATH_SELECTED_TE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET Models to test ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recipe_unet_itr(p):\n",
    "    unet_model = \"{}{}\".format(DIR_RAW, p)\n",
    "    clip_model = \"{}{}\".format(MECHA_MODEL_PATH_SELECTED_TE, MECHA_MODEL_EXT)\n",
    "    casted_unet_model = sd_mecha.model(unet_model, MECHA_IS_SDXL)\n",
    "    casted_clip_model = sd_mecha.model(clip_model, MECHA_IS_SDXL)\n",
    "    recipe_te2 = sd_mecha.weighted_sum(casted_clip_model, casted_unet_model, alpha=TE2_ALPHA, dtype=g_precision_while_merge, device=g_device)\n",
    "    return pick_vae(recipe_te2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped generating unused recipes.\n"
     ]
    }
   ],
   "source": [
    "# N models\n",
    "if SKIP_GEN_MANUAL_FILTER:\n",
    "    print(\"Skipped generating unused recipes.\")\n",
    "else:\n",
    "    for i in range(len(MODEL_LIST_RAW)):\n",
    "        set_rmk(rmk_unet(i+1), make_recipe_unet_itr(MODEL_LIST_RAW[i]))\n",
    "        sd_mecha.serialize_and_save(recipe_mapping[rmk_unet(i+1)], get_unet_itr_path(RECIPE_PATH_UNET_ITR,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model ###\n",
    "\n",
    "- 2 models will be produced for validation. The real e2e and staged merging should yield same model within floating errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recipe_final():\n",
    "    raw_models = list(map(lambda p: \"{}{}\".format(DIR_RAW,p),MODEL_LIST_RAW))\n",
    "    models_unet = [raw_models[i-1] for i in MODEL_SELECTION_UNET]\n",
    "\n",
    "    clip_model = \"{}{}\".format(MECHA_MODEL_PATH_SELECTED_TE, MECHA_MODEL_EXT)\n",
    "    casted_clip_model = sd_mecha.model(clip_model, MECHA_IS_SDXL)\n",
    "\n",
    "    if ALGO_ACTIVATED == ALGO_AVERAGE:\n",
    "        recipe_unet = models_unet[0]\n",
    "        casted_recipe_unet = sd_mecha.model(recipe_unet, MECHA_IS_SDXL)\n",
    "        for i, model in enumerate(models_unet[1:], start=2):\n",
    "            casted_model = sd_mecha.model(model, MECHA_IS_SDXL)\n",
    "            casted_recipe_unet = sd_mecha.weighted_sum(casted_model, casted_recipe_unet, alpha=(i-1)/i, dtype=g_precision_while_merge, device=g_device)\n",
    "    elif ALGO_ACTIVATED == ALGO_NAVG:\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.n_average(*casted_models_unet, **KWARGS_NAVG)\n",
    "    elif ALGO_ACTIVATED == ALGO_MEDIAN:\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.geom_median(*casted_models_unet, **KWARGS_MEDIAN)\n",
    "    elif ALGO_ACTIVATED == ALGO_MODELSTOCK:\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.model_stock_n_models(CASTED_OG_MODEL, *casted_models_unet, **KWARGS_MODELSTOCK)\n",
    "    elif ALGO_ACTIVATED == ALGO_TIES:\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.add_difference_ties(CASTED_OG_MODEL, *casted_models_unet, **KWARGS_TIES)\n",
    "    elif ALGO_ACTIVATED == ALGO_DARE:\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.ties_with_dare(CASTED_OG_MODEL, *casted_models_unet, **KWARGS_DARE)\n",
    "    else:\n",
    "        raise Exception(\"Algorithm {} is not supported.\".format(ALGO_ACTIVATED))  \n",
    "\n",
    "    final_model = sd_mecha.weighted_sum(casted_clip_model, casted_recipe_unet, alpha=TE2_ALPHA, dtype=g_precision_while_merge, device=g_device)\n",
    "\n",
    "    return pick_vae(final_model)\n",
    "\n",
    "def make_recipe_e2e():\n",
    "    raw_models = list(map(lambda p: \"{}{}\".format(DIR_RAW,p),MODEL_LIST_RAW))\n",
    "\n",
    "    models_te0 = [raw_models[i-1] for i in MODEL_SELECTION_TE0]\n",
    "    models_te1 = [raw_models[i-1] for i in MODEL_SELECTION_TE1]\n",
    "    models_unet = [raw_models[i-1] for i in MODEL_SELECTION_UNET]\n",
    "   \n",
    "    if ALGO_ACTIVATED == ALGO_AVERAGE:\n",
    "        recipe_te0 = models_te0[0]\n",
    "        casted_recipe_te0 = sd_mecha.model(recipe_te0, MECHA_IS_SDXL)\n",
    "        for i, model in enumerate(models_te0[1:], start=2):\n",
    "            casted_model = sd_mecha.model(model, MECHA_IS_SDXL)\n",
    "            casted_recipe_te0 = sd_mecha.weighted_sum(casted_model, casted_recipe_te0, alpha=(i-1)/i, dtype=g_precision_while_merge, device=g_device)\n",
    "        recipe_te1 = models_te1[0]\n",
    "        casted_recipe_te1 = sd_mecha.model(recipe_te1, MECHA_IS_SDXL)\n",
    "        for i, model in enumerate(models_te1[1:], start=2):\n",
    "            casted_model = sd_mecha.model(model, MECHA_IS_SDXL)\n",
    "            casted_recipe_te1 = sd_mecha.weighted_sum(casted_model, casted_recipe_te1, alpha=(i-1)/i, dtype=g_precision_while_merge, device=g_device)\n",
    "        recipe_unet = models_unet[0]\n",
    "        casted_recipe_unet = sd_mecha.model(recipe_unet, MECHA_IS_SDXL)\n",
    "        for i, model in enumerate(models_unet[1:], start=2):\n",
    "            casted_model = sd_mecha.model(model, MECHA_IS_SDXL)\n",
    "            casted_recipe_unet = sd_mecha.weighted_sum(casted_model, casted_recipe_unet, alpha=(i-1)/i, dtype=g_precision_while_merge, device=g_device)\n",
    "    elif ALGO_ACTIVATED == ALGO_NAVG:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.n_average(*casted_models_te0, **KWARGS_NAVG)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.n_average(*casted_models_te1, **KWARGS_NAVG)\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.n_average(*casted_models_unet, **KWARGS_NAVG)\n",
    "    elif ALGO_ACTIVATED == ALGO_MEDIAN:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.geom_median(*casted_models_te0, **KWARGS_MEDIAN)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.geom_median(*casted_models_te1, **KWARGS_MEDIAN)\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.geom_median(*casted_models_unet, **KWARGS_MEDIAN)\n",
    "    elif ALGO_ACTIVATED == ALGO_MODELSTOCK:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.model_stock_n_models(CASTED_OG_MODEL, *casted_models_te0, **KWARGS_MODELSTOCK)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.model_stock_n_models(CASTED_OG_MODEL, *casted_models_te1, **KWARGS_MODELSTOCK)\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.model_stock_n_models(CASTED_OG_MODEL, *casted_models_unet, **KWARGS_MODELSTOCK)\n",
    "    elif ALGO_ACTIVATED == ALGO_TIES:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.add_difference_ties(CASTED_OG_MODEL, *casted_models_te0, **KWARGS_TIES)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.add_difference_ties(CASTED_OG_MODEL, *casted_models_te1, **KWARGS_TIES)\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.add_difference_ties(CASTED_OG_MODEL, *casted_models_unet, **KWARGS_TIES)\n",
    "    elif ALGO_ACTIVATED == ALGO_DARE:\n",
    "        casted_models_te0 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te0]\n",
    "        casted_recipe_te0 = sd_mecha.ties_with_dare(CASTED_OG_MODEL, *casted_models_te0, **KWARGS_DARE)\n",
    "        casted_models_te1 = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_te1]\n",
    "        casted_recipe_te1 = sd_mecha.ties_with_dare(CASTED_OG_MODEL, *casted_models_te1, **KWARGS_DARE)\n",
    "        casted_models_unet = [sd_mecha.model(model, MECHA_IS_SDXL) for model in models_unet]\n",
    "        casted_recipe_unet = sd_mecha.ties_with_dare(CASTED_OG_MODEL, *casted_models_unet, **KWARGS_DARE)\n",
    "    else:\n",
    "        raise Exception(\"Algorithm {} is not supported.\".format(ALGO_ACTIVATED))  \n",
    "\n",
    "    e2e_model = \"{}{}\".format(DIR_RAW,MODEL_LIST_RAW[MODEL_SELECTION_VAE - 1]) \n",
    "    casted_e2e_model = sd_mecha.model(e2e_model, MECHA_IS_SDXL)\n",
    "\n",
    "    casted_e2e_model = sd_mecha.weighted_sum(casted_e2e_model, casted_recipe_unet, alpha=TE2_ALPHA, dtype=g_precision_while_merge, device=g_device)\n",
    "    casted_e2e_model = sd_mecha.weighted_sum(casted_e2e_model, casted_recipe_te0, alpha=TE0_ALPHA_INVERTED, dtype=g_precision_while_merge, device=g_device)\n",
    "    casted_e2e_model = sd_mecha.weighted_sum(casted_e2e_model, casted_recipe_te1, alpha=TE1_ALPHA_INVERTED, dtype=g_precision_while_merge, device=g_device)\n",
    "\n",
    "    #Note that there is no pick_vae\n",
    "    return casted_e2e_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped generating unused recipes.\n"
     ]
    }
   ],
   "source": [
    "if SKIP_GEN_MANUAL_FILTER:\n",
    "    print(\"Skipped generating unused recipes.\")\n",
    "else:\n",
    "    set_rmk(rmk_f(), make_recipe_final())\n",
    "    sd_mecha.serialize_and_save(recipe_mapping[rmk_f()], RECIPE_PATH_FINAL)\n",
    "    set_rmk(rmk_e2e(), make_recipe_e2e())\n",
    "    sd_mecha.serialize_and_save(recipe_mapping[rmk_e2e()], RECIPE_PATH_E2E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for action ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Average ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Saving to F:\\NOVELAI\\astolfo_mix\\sdxl\\x255a-AstolfoMix-25022801-1458190.safetensors\n",
      "Merging recipe: 100%|██████████| 2515/2515 [39:03:56<00:00, 55.92s/it, key=model.diffusion_model.output_blocks.7.0.out_layers.3.weight, shape=[320, 320, 3, 3]]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge time: 140645 sec\n"
     ]
    }
   ],
   "source": [
    "tss = time.time()\n",
    "\n",
    "if MODE_RAW in MODE_ACTIVATED:\n",
    "    if os.path.isfile(OS_MODEL_PATH_RAW):\n",
    "        print(\"Merged model is present. Skipping.\")\n",
    "    else:\n",
    "        scheduler.merge_and_save(recipe_mapping[rmk_raw()], output=MECHA_MODEL_PATH_RAW, fallback_model=FALLBACK_AS_OG_MODEL, save_dtype=g_precision_final_model, total_buffer_size=g_total_buffer_size, threads=g_threads)\n",
    "else:\n",
    "    print(\"This session is not activated. Skipping.\")\n",
    "\n",
    "tse = time.time()\n",
    "print(\"Merge time: {} sec\".format(int(tse - tss)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Models to test ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This session is not activated. Skipping.\n",
      "Merge time: 0 sec\n"
     ]
    }
   ],
   "source": [
    "tss = time.time()\n",
    "\n",
    "if MODE_CLIP in MODE_ACTIVATED:\n",
    "    # 3N models\n",
    "    #for i in tqdm(range(len(MODEL_LIST_RAW)), desc=\"Iterlating raw model list to swap TEs\"):\n",
    "    #    for j in tqdm(range(len(N_CLIP)), desc=\"Making models with swapped raw TEs\"):\n",
    "    for i in range(len(MODEL_LIST_RAW)):\n",
    "        for j in range(len(N_CLIP)):    \n",
    "            if os.path.isfile(get_te_itr_path(OS_MODEL_PATH_TE_ITR,i,j)):\n",
    "                print(\"Merged model is present. Skipping.\")\n",
    "            else:        \n",
    "                scheduler.merge_and_save(recipe_mapping[rmk_te(i+1,j)], output=get_te_itr_path(MECHA_MODEL_PATH_TE_ITR,i,j), fallback_model=FALLBACK_AS_OG_MODEL, save_dtype=g_precision_final_model, total_buffer_size=g_total_buffer_size, threads=g_threads)\n",
    "else:\n",
    "    print(\"This session is not activated. Skipping.\")\n",
    "\n",
    "tse = time.time()\n",
    "print(\"Merge time: {} sec\".format(int(tse - tss)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picked CLIP Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This session is not activated. Skipping.\n",
      "Merge time: 0 sec\n"
     ]
    }
   ],
   "source": [
    "tss = time.time()\n",
    "\n",
    "if MODE_CLIP in MODE_ACTIVATED:\n",
    "    if os.path.isfile(OS_MODEL_PATH_SELECTED_TE):\n",
    "        print(\"Merged model is present. Skipping.\")\n",
    "    else:\n",
    "        scheduler.merge_and_save(recipe_mapping[rmk_ste()], output=MECHA_MODEL_PATH_SELECTED_TE, fallback_model=FALLBACK_AS_OG_MODEL, save_dtype=g_precision_final_model, total_buffer_size=g_total_buffer_size, threads=g_threads)\n",
    "else:\n",
    "    print(\"This session is not activated. Skipping.\")\n",
    "\n",
    "tse = time.time()\n",
    "print(\"Merge time: {} sec\".format(int(tse - tss)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET Models to test ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This session is not activated. Skipping.\n",
      "Merge time: 0 sec\n"
     ]
    }
   ],
   "source": [
    "tss = time.time()\n",
    "\n",
    "if MODE_UNET in MODE_ACTIVATED:\n",
    "    # N models\n",
    "    #for i in tqdm(range(len(MODEL_LIST_RAW)), desc=\"Iterlating raw model list to swap UNETs\"):\n",
    "    for i in range(len(MODEL_LIST_RAW)):\n",
    "        if os.path.isfile(get_unet_itr_path(OS_MODEL_PATH_UNET_ITR,i)):\n",
    "            print(\"Merged model is present. Skipping.\")\n",
    "        else:\n",
    "            scheduler.merge_and_save(recipe_mapping[rmk_unet(i+1)], output=get_unet_itr_path(MECHA_MODEL_PATH_UNET_ITR,i), fallback_model=FALLBACK_AS_OG_MODEL, save_dtype=g_precision_final_model, total_buffer_size=g_total_buffer_size, threads=g_threads)\n",
    "else:\n",
    "    print(\"This session is not activated. Skipping.\")\n",
    "\n",
    "tse = time.time()\n",
    "print(\"Merge time: {} sec\".format(int(tse - tss)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./x255a-AstolfoMix-x255te0x255te1-25022801-1458190 ./x255-AstolfoMix-x255te0x255te1-25022801-1458190\n"
     ]
    }
   ],
   "source": [
    "print (MECHA_MODEL_PATH_SELECTED_TE, MECHA_MODEL_PATH_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This session is not activated. Skipping.\n",
      "Merge time: 0 sec\n"
     ]
    }
   ],
   "source": [
    "tss = time.time()\n",
    "\n",
    "if MODE_FINAL in MODE_ACTIVATED:\n",
    "    if os.path.isfile(OS_MODEL_PATH_FINAL):\n",
    "        print(\"Merged model is present. Skipping.\")\n",
    "    elif os.path.isfile(OS_MODEL_PATH_SELECTED_TE):\n",
    "        scheduler.merge_and_save(recipe_mapping[rmk_f()], output=MECHA_MODEL_PATH_FINAL, fallback_model=FALLBACK_AS_OG_MODEL, save_dtype=g_precision_final_model, total_buffer_size=g_total_buffer_size, threads=g_threads)\n",
    "    else:\n",
    "        print(\"Selected TE is not present. Skipping.\")\n",
    "else:\n",
    "    print(\"This session is not activated. Skipping.\")\n",
    "\n",
    "tse = time.time()\n",
    "print(\"Merge time: {} sec\".format(int(tse - tss)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This session is not activated. Skipping.\n",
      "Merge time: 0 sec\n"
     ]
    }
   ],
   "source": [
    "tss = time.time()\n",
    "\n",
    "if MODE_FINAL in MODE_ACTIVATED:\n",
    "    if os.path.isfile(OS_MODEL_PATH_E2E):\n",
    "        print(\"Merged model is present. Skipping.\")\n",
    "    else:\n",
    "        scheduler.merge_and_save(recipe_mapping[rmk_e2e()], output=MECHA_MODEL_PATH_E2E, fallback_model=FALLBACK_AS_OG_MODEL, save_dtype=g_precision_final_model, total_buffer_size=g_total_buffer_size, threads=g_threads)\n",
    "else:\n",
    "    print(\"This session is not activated. Skipping.\")\n",
    "\n",
    "tse = time.time()\n",
    "print(\"Merge time: {} sec\".format(int(tse - tss)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full operation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 140645 sec\n"
     ]
    }
   ],
   "source": [
    "te = time.time()\n",
    "print(\"Total time: {} sec\".format(int(te - ts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "novelai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
