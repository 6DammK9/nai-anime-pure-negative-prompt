{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge as unprune #\n",
    "\n",
    "## Abstract ##\n",
    "\n",
    "- Special case of `uniform_merge`. Some pruned SDXL models cannot be merged via A1111, or open by [toolkit](https://github.com/arenasys/stable-diffusion-webui-model-toolkit). We use [OpenDalle](https://huggingface.co/dataautogpt3/OpenDalleV1.1) for example. We use [SDXL Base 1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) as base model, then \"merge\" the model with \"either aplha=0 or 1\" (model list is unsorted), a.k.a use foreigner model weight directly.\n",
    "\n",
    "## Recipe ##\n",
    "\n",
    "- `_x25-sd_xl_base_1.0`: Complete base model.\n",
    "\n",
    "- `_x04-OpenDalleV1.1`: Model to be un-pruned.\n",
    "\n",
    "## Required libraries ##\n",
    "\n",
    "- `torch>=2.0.1`\n",
    "- `tensordict`\n",
    "- `sd-mecha` (Commit `ead8ad7caba900ab0a40e2dfcae04b9d50fae2e6` only! `git clone`, and then `git checkout ead8ad7caba900ab0a40e2dfcae04b9d50fae2e6`, and copy 1 layer upward to `./sd_mecha/`)\n",
    "- [safetensors](https://huggingface.co/docs/safetensors/index)\n",
    "- [diffusers](https://huggingface.co/docs/diffusers/installation)\n",
    "- [pytorch](https://pytorch.org/get-started/locally/#windows-python)\n",
    "\n",
    "## WTF why and will it work? ##\n",
    "\n",
    "- Yes. [It is part of my research](./README_XL.md).\n",
    "- Image comparasion will be listed there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Is dependency fufilled?\n",
    "import torch\n",
    "import tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main module.\n",
    "import sd_mecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for OMP: Error #15\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll disable pruning to let [toolkit](https://github.com/arenasys/stable-diffusion-webui-model-toolkit) support the merged model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_device = \"cuda:0\" #\"cpu\"\n",
    "g_prune = False\n",
    "g_merged_model = \"_x04-fixed\" #.safetensors\n",
    "g_precision = 16 #fp16, forwarded from sd-meh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"../stable-diffusion-webui/tmp/astolfo_mix/sdxl/_x04/\"\n",
    "model_type = torch.float16 if \"cuda\" in g_device else torch.float # CPU doesn't support FP16 / FP8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring model inside a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = os.listdir(model_folder)\n",
    "# Exclude yaml.\n",
    "model_list = list(filter(lambda p: p.endswith(\".ckpt\") or p.endswith(\".safetensors\") or p.endswith(\".bin\"), model_list))\n",
    "if len(model_list) < 2:\n",
    "    #Special case: Model fix\n",
    "    model_list.append(model_list[0])\n",
    "    #raise Exception(\"Need at least 2 models for merge.\")\n",
    "\n",
    "#model_list = list(map(lambda p: os.path.splitext(os.path.basename(p))[0], model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 models found.\n"
     ]
    }
   ],
   "source": [
    "#model_list\n",
    "print(\"{} models found.\".format(len(model_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up merge receipe and merge scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = model_list\n",
    "\n",
    "merge = models[0]\n",
    "for i, model in enumerate(models[1:], start=2):\n",
    "    merge = sd_mecha.weighted_sum(merge, model, alpha=0)\n",
    "\n",
    "scheduler = sd_mecha.MergeScheduler(\n",
    "    base_dir=model_folder,\n",
    "    device=g_device,\n",
    "    prune=g_prune,\n",
    "    precision=g_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 5448.66it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420316.16it/s]\n"
     ]
    }
   ],
   "source": [
    "ts = time.time()\n",
    "scheduler.merge_and_save(merge, output_path=g_merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18 sec\n"
     ]
    }
   ],
   "source": [
    "te = time.time()\n",
    "print(\"time: {} sec\".format(int(te - ts)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
