{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Average merger #\n",
    "\n",
    "As known as \"one click Uniform Merge\".\n",
    "\n",
    "## Abstract ##\n",
    "\n",
    "- Self explained. Using `sd-mecha` as main library. **Thank you [@ljleb](https://github.com/ljleb/) for the codebase.**\n",
    "- **No need to waste 1TB+ of disk space for pariwise merging.** However you should know the \"model pool\", otherwise it is likely result in a worse model. It takes around 8 miuntes to merge 40 SDXL models, comparing to 47 minutes on A1111 WebUI.\n",
    "- VRAM usage: *A lot, will drain up VRAM but no OOM error.*\n",
    "- I intentionally make it into Python notebook because I can keep explaining stuffs inplace, like most AI / ML articles. [Base code is available here.](https://github.com/ljleb/sd-mecha/blob/main/examples/n_average.py) ~~I know this is also a nice testing script / example for a library.~~\n",
    "\n",
    "## Required libraries ##\n",
    "\n",
    "- `torch>=2.0.1`\n",
    "- `tensordict`\n",
    "- `sd-mecha` (Commit `ead8ad7caba900ab0a40e2dfcae04b9d50fae2e6` only! `git clone`, and then `git checkout ead8ad7caba900ab0a40e2dfcae04b9d50fae2e6`, and copy 1 layer upward to `./sd_mecha/`)\n",
    "- [safetensors](https://huggingface.co/docs/safetensors/index)\n",
    "- [diffusers](https://huggingface.co/docs/diffusers/installation)\n",
    "- [pytorch](https://pytorch.org/get-started/locally/#windows-python)\n",
    "\n",
    "## WTF why and will it work? ##\n",
    "\n",
    "- Yes. [It is part of my research](./README_XL.md).\n",
    "- Image comparasion will be listed there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Is dependency fufilled?\n",
    "import torch\n",
    "import tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main module.\n",
    "import sd_mecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for OMP: Error #15\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll disable pruning to let [toolkit](https://github.com/arenasys/stable-diffusion-webui-model-toolkit) support the merged model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_device = \"cuda:0\" #\"cpu\"\n",
    "g_prune = False\n",
    "g_merged_model = \"x43-AstolfoMix-e2e\" #.safetensors\n",
    "g_precision = 16 #fp16, forwarded from sd-meh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"../stable-diffusion-webui/tmp/astolfo_mix/sdxl/unet/\"\n",
    "model_type = torch.float16 if \"cuda\" in g_device else torch.float # CPU doesn't support FP16 / FP8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring model inside a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = os.listdir(model_folder)\n",
    "# Exclude yaml.\n",
    "model_list = list(filter(lambda p: p.endswith(\".ckpt\") or p.endswith(\".safetensors\") or p.endswith(\".bin\"), model_list))\n",
    "if len(model_list) < 2:\n",
    "    #Special case: Model fix\n",
    "    #model_list.append(model_list[0])\n",
    "    raise Exception(\"Need at least 2 models for merge.\")\n",
    "\n",
    "#model_list = list(map(lambda p: os.path.splitext(os.path.basename(p))[0], model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 models found.\n"
     ]
    }
   ],
   "source": [
    "#model_list\n",
    "print(\"{} models found.\".format(len(model_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up merge receipe and merge scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = model_list\n",
    "\n",
    "merge = models[0]\n",
    "for i, model in enumerate(models[1:], start=2):\n",
    "    merge = sd_mecha.weighted_sum(merge, model, alpha=1/i)\n",
    "\n",
    "scheduler = sd_mecha.MergeScheduler(\n",
    "    base_dir=model_folder,\n",
    "    device=g_device,\n",
    "    prune=g_prune,\n",
    "    precision=g_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stage 1: 100%|██████████| 2515/2515 [00:00<00:00, 3826.60it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420282.66it/s]\n",
      "stage 1: 100%|██████████| 2515/2515 [00:00<00:00, 3903.61it/s]\n",
      "stage 2: 100%|██████████| 2516/2516 [00:00<00:00, 420466.53it/s]\n",
      "stage 1: 100%|██████████| 2515/2515 [00:00<00:00, 4584.95it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420282.66it/s]\n",
      "stage 1: 100%|██████████| 2515/2515 [00:00<00:00, 3473.45it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420316.16it/s]\n",
      "stage 1: 100%|██████████| 2515/2515 [00:00<00:00, 4983.65it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420282.66it/s]\n",
      "stage 1: 100%|██████████| 2515/2515 [00:00<00:00, 3576.91it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 360268.94it/s]\n",
      "stage 1: 100%|██████████| 2515/2515 [00:00<00:00, 5837.33it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 360268.94it/s]\n",
      "stage 1: 100%|██████████| 2515/2515 [00:00<00:00, 4147.58it/s]\n",
      "stage 2: 100%|██████████| 2516/2516 [00:00<00:00, 420382.78it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4733.06it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 360305.86it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4586.78it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420349.65it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4689.08it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504359.29it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4441.42it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504335.18it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4898.50it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420332.90it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 3991.66it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 360232.03it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 5390.43it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504359.29it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 3543.16it/s]\n",
      "stage 2: 100%|██████████| 2516/2516 [00:00<00:00, 420500.03it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4628.87it/s]\n",
      "stage 2: 100%|██████████| 2514/2514 [00:00<00:00, 504158.75it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 5233.88it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504407.52it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4449.26it/s]\n",
      "stage 2: 100%|██████████| 2514/2514 [00:00<00:00, 315099.22it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4733.08it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504335.18it/s]\n",
      "stage 1: 100%|██████████| 2516/2516 [00:00<00:00, 4102.01it/s]\n",
      "stage 2: 100%|██████████| 3308/3308 [00:00<00:00, 122841.99it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5079.41it/s]\n",
      "stage 2: 100%|██████████| 2516/2516 [00:00<00:00, 420449.77it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 6153.71it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420232.43it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 4892.11it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504359.29it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5509.72it/s]\n",
      "stage 2: 100%|██████████| 2516/2516 [00:00<00:00, 360387.57it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 4549.87it/s]\n",
      "stage 2: 100%|██████████| 2516/2516 [00:00<00:00, 420466.53it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 4884.91it/s]\n",
      "stage 2: 100%|██████████| 3308/3308 [00:00<00:00, 473864.67it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5402.04it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504407.52it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5048.48it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 360256.64it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5689.28it/s]\n",
      "stage 2: 100%|██████████| 2516/2516 [00:00<00:00, 420466.53it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5748.45it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420282.66it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5583.93it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504311.07it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5922.95it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504286.96it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 4494.38it/s]\n",
      "stage 2: 100%|██████████| 2516/2516 [00:00<00:00, 504487.47it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5546.57it/s]\n",
      "stage 2: 100%|██████████| 2514/2514 [00:00<00:00, 504158.75it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 4884.91it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420282.66it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 4738.36it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 420299.41it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 6354.12it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 252155.53it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 4765.59it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 360232.03it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5002.79it/s]\n",
      "stage 2: 100%|██████████| 2514/2514 [00:00<00:00, 504303.42it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5997.92it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 504359.29it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 5358.40it/s]\n",
      "stage 2: 100%|██████████| 2515/2515 [00:00<00:00, 360268.94it/s]\n",
      "stage 1: 100%|██████████| 3308/3308 [00:00<00:00, 6982.84it/s]\n",
      "stage 2: 100%|██████████| 2514/2514 [00:00<00:00, 210057.78it/s]\n"
     ]
    }
   ],
   "source": [
    "ts = time.time()\n",
    "scheduler.merge_and_save(merge, output_path=g_merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 608 sec\n"
     ]
    }
   ],
   "source": [
    "te = time.time()\n",
    "print(\"time: {} sec\".format(int(te - ts)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
