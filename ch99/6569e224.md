# "anything-v3" Pure Negative Prompt #

- HF mirror [Linaqruf/anything-v3.0](https://huggingface.co/Linaqruf/anything-v3.0). Note that both of them are not related to the author. The author is ~~not revealed outside China~~ [proven by me](../ch02/any3_qqid.md). **This mirror is officially deleted on 24-01-2023.**

- [andite/anything-v4.0](https://huggingface.co/andite/anything-v4.0) has **no connection to this model**. The author has contaced me also. I won't create a seperate article for the *spiritual successor*. [The original mirror will be removed.](https://huggingface.co/Linaqruf/anything-v3.0/discussions/133).

- However someone [mirrored all of them above and called it "v5.0"](https://huggingface.co/AdamOswald1/anything-v5.0). Long live internet lol. ~~3^2 + 4^2 = 5^2~~

- [Official successor AnythingV5.](https://civitai.com/models/9409/anything-v5-or-anything-diffusion-original). He claimed that "worse then Any3", looks like not the case?

- **Misinformation confirmed. Leave for inspiration.** ~~Seems that the model has been [fine tuned in CLIP level.](https://towardsdatascience.com/how-to-train-your-clip-45a451dcd303). Otherwise [it is pre-trained from ground up, which is not likely.](https://wandb.ai/capecape/train_sd/reports/How-to-Train-a-Conditional-Diffusion-Model-from-Scratch--VmlldzoyNzIzNTQ1).~~
- This model is a "larger merge" by using "Checkpoint Merger": `merge(momoko-e,f222?,more?)` = `merge(nai,mmk-e fix,f222?,more?)` with **a secret ratio.**
- As it is a merged model [JP](https://signyamo.blog/sd_merge-models/), [EN](https://www.reddit.com/r/StableDiffusion/comments/xss6bl/checkpoint_merging_comparative/) ,[CH](https://www.bilibili.com/read/mobile?id=19099066), [Models](https://rentry.org/sdmodels), [it is not a graceful ML approach](https://stackoverflow.com/questions/48358874/merge-weights-of-same-model-trained-on-2-different-computers-using-tensorflow 
). [It should be done in ensemble or follow the "fewshot" approach.](https://towardsdatascience.com/neural-networks-ensemble-33f33bea7df3)
- It has **bias** on human (~~anime girls?~~). Objects are possible, but the emphassis ratio should be changed (NAI is 1:1 or even human 1.0: 0.8 object ~~this model is unknown yet~~).
- For "non girl" (obviously my journey with Astolfo the boy), ~~looks like the *emphassis level* remains the same really need to increase...~~ see next sentence.
- (Dedicated to Astolfo? But worth to mention here) The "bias" on human is something like *you will get multiple human instead of blurry background*. Stating `1boy` `1girl` `solo` will not be effective (it can glitch!). More troublesome, if AI think that the character doesn't fit the gender, it will create one more. Current solution is using some *gender specific words* (`muscular`, `abs`), and expect a lower yield rate.
- Usually **64 STEP** for PoC (Under `-9*0.105`), and depends on serious rendering (this is a hyperparameter). No maximum value, depends on how confidient I am.

|Dimension|Sample size|Pattern|Object or Sceneary|Malformed Human|Legit Human|Body shape|
|---|---|---|---|---|---|---|
|1024x576|20|0|0|2|18|Normal|
|512x512|20|0|0|0|20|Normal|

- ~~For the "0.102" (`24x[`) approch, follow the scale with base 8.0. Scaled with area, and not likely correlated to prompts. Maybe raised to `12x[`, if *non girl* is somewhat difficult to generate.~~ CFG recommended to scale with 8.0.

|Dimension|CFG Recommended|
|---|---|
|512x512|8.0|
|768x768|18.0|

- **The negative prompt can be arbitary low, but must be greater then zero.** Tested with `1e-16`, still looking fine. To make sure the negative prompts has minimal effect and reduce character length, I choose `1e-4` instaed. `0.1` may still have some slight effect.

```
(bad:0.0001), (comic:0.0001), (cropped:0.0001), (error:0.0001), (extra:0.0001), (low:0.0001), (lowres:0.0001), (speech:0.0001), (worst:0.0001)
```

- I'm not a fan of "fragmented" art style (*impressionism*?). The AI model still need some area / color control for generating multiple subjects. But it does catch eyes.

- The "art style" is even more bright (tends to use bright color, which is *popular in image segmentation / computer vision*, or *Fauvism*?).

- From my point of view, since the "AI hands" is rooted on the model's structure (definitely need some CNN to cater for anatomy, fully connected layers for abstract ideas, instedad of a general transformer based CLIP). Therefore, *I trade the details for a far better art style.*
