# A quick quiz for myself (CivitAI Article 4751) # 

- [Article / question list.](https://civitai.com/articles/4751/stable-diffusion-artificial-intelligence-stupid-questions)

## Main Session ##

0. If a question worth answering but never answered precisely (may not correct!), it is always a good question. [Generative artificial intelligence](https://en.wikipedia.org/wiki/Generative_artificial_intelligence) was a old concept, but only rise awareness for general public after 2023. It worths to "explain a bit more" (but only a little bit). Disclaimer: I'm NOT AN ARTIST. I'm a programmer ~~and programmer has no life.~~

1. *SD is an artificial intelligence machine learning program, right?* YES. In precise, it is an [AI model](https://www.ibm.com/topics/ai-model).

1.0 However, in *pop culture*, it becomes a [genre](https://en.wikipedia.org/wiki/Genre) or [category](https://www.dictionary.com/browse/category) of models, sharing same [model archetiture](https://www.hopsworks.ai/dictionary/model-architecture) but different in [model weight](https://machine-learning.paperspace.com/wiki/weights-and-biases). For example, [Pony Diffusion V6 XL](https://civitai.com/models/257749?modelVersionId=290640) is a model [finetuned](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)) from SDXL. 

2. *So where does the machine learning happen?* [It is deep.](https://www.coursera.org/articles/data-science-vs-machine-learning). **The whole "story" is Machine Learning**:
- [Math equations on whiteboard](https://arxiv.org/abs/2307.01952)
- [Crawing image through the internet and not being sued](https://laion.ai/)
- [Burning GPU until CEO just leave before product release](https://www.theregister.com/2024/04/03/stability_ai_bills/)
- [Looking for the "prediction", and revise its performance](https://decrypt.co/150575/greg-rutkowski-removed-from-stable-diffusion-but-brought-back-by-ai-artists)
- All of them combined is the [lifecycle of machine learning (subset of data science)](https://www.institutedata.com/blog/5-steps-in-data-science-lifecycle/).

2.1 *Or does all the ML happen pre-release?* Ture. It is called [pretrining](https://aiml.com/what-do-you-mean-by-pretraining-finetuning-and-transfer-learning-in-the-context-of-machine-learning-or-language-modeling/). The article is about NLP, but the "SD" in the culture is the exact same path. "General images" (pretraining) > "Anime images" (larger finetuned / merged model) > "your style" (smaller finetuned model / LoRA).

2.2 *Why we need so many LoRAs?* Capability of a single model is capped within its trainined dataset (images). If your desired content is out of there (e.g. An anime character in recent anime series / someone have opt-out for the evil image dataset), you must *finetune* it. 
2.2.1 Such "small tasks" can be archieved with full model (GB in size) or LoRA (MB in size), then [obviously](https://www.quora.com/What-does-clearly-obviously-mean-in-a-mathematical-proof) public will choose to save disk size instead of [ultimate precision](https://huggingface.co/waifu-diffusion/wd40).

2.3 *Is the CivitAI (or any remote) service then always going to be better for general tasks?* [Maybe better?](https://tracxn.com/d/companies/civitai/__lPqZEx0Rc2Ctj30Dl5dV1LSbSanCD2VpFL_MkcCggDs) Sure it has hosted so many GPUs in their cloud platform. [This service is not CivitAI, but it has 256x H100s which your RTX4090 won't stand a chance.](https://blog.novelai.net/anlatan-acquires-hgx-h100-cluster-4b7a2e6a631e) [If you concern about privacy, your local machine must be better.](https://www.siliconera.com/dlsite-credit-card-usage-temporarily-suspended/)

3. *What does SD 1.5 do best and worst?* I leave it to artist. However you can compare [my SD1.5](https://civitai.com/models/155604/astolfomix) , [my SD2.1](https://civitai.com/models/255754/astolfomix-sd2) and [my SDXL](https://civitai.com/models/309514/astolfomix-xl) which are produced with almost the exact same method i.e. "average of the models I've found, and generate general images." ~~Use 1.5 until you are not satisfied.~~

3.1 *"never" list*: [It is all about bias.](https://www.ibm.com/topics/ai-bias) Just look for the internet. If you are against internet trends, it won't work. [It is not a "skill issue".](https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/) In the whiteboard, AI only cares what it have learnt. Many (not most) models are fine with *arbitrary prompting style.* [AI breaks your prompt into tokens and embeddings in byte form, subword scale.](https://huggingface.co/docs/transformers/tokenizer_summary) [Pony Diffusion V6 XL](https://civitai.com/models/257749?modelVersionId=290640) earnt its own category because it made it to the exact opposite. [Maybe even further, in "hash"](https://rentry.org/ponyxl_loras_n_stuff#reverse-engineered-hashed-tokens). Note that "Hash" isvalid academically. It is just token collision.

4. *I understand that I don't know how to use it well but again, I didn't think this was going to be a fight.* Nah. SD (even the unreleased SD3) will never consistantly ouputing 5 fingers and 2 hands. It is *not even tried* in whiteboard. [That is exactly what ControlNet does](https://arxiv.org/abs/2302.05543), by adding [mask](https://onceuponanalgorithm.org/guide-stable-diffusion-inpaint-masked-content-options-explained/) while the computation process. 
4.1 *And this isn't gen 1, more like 20. 5 tries or so just to get him to look at the camera.* Sometimes it don't appear after 200 tries, because it can't. I have done it through my journey, single click and go to bed. Common practice is below 20, but I am daily 100 or even 200 for a [distribution](https://en.wikipedia.org/wiki/Probability_distribution) of contents. I will skip explaining why [SD](https://github.com/CompVis/stable-diffusion/blob/main/ldm/models/diffusion/ddpm.py) is a [probabilistic model](https://arxiv.org/abs/2006.11239). [You can even have legit content without any prompt.](https://github.com/6DammK9/nai-anime-pure-negative-prompt)

0. Thanks for reading to the last. Hope you are fine with the red pill.

## Follow up ##

[Full parameters here](https://www.pixiv.net/en/artworks/114277540). Took me 5 minues to generate with 2080 ti. However 256 steps are overkill. 48 steps are fine. 21:9 with over the original intended resolution (1792x768x2.0 over original 512x512x1.0) is suprising, showing the potential of the model (architecture).

Why SD 1.5 still being compertitive:

- There was [an incident](https://www.reddit.com/r/StableDiffusion/comments/xysavk/has_anyone_tried_the_novelai_leak/) caused one of the greatest [alignement](https://research.ibm.com/blog/what-is-alignment-ai)

- There was [no LoRA](https://huggingface.co/docs/diffusers/training/dreambooth), or [legit finetuning tools](https://github.com/kohya-ss/sd-scripts), forcing people merging models (the theories you've seen in CivitAI instead of arXiv), and the [iterlation](https://radiopaedia.org/articles/iteration-machine-learning) between merging / finetuning somehow benefit the model performance.

In comparasion to SDXL:
- Obviously there is no "alignment". I know [linaqruf](https://civitai.com/models/260267/animagine-xl-v31) and [kohaku](https://civitai.com/models/332076/kohaku-xl-delta) through the communities, they talked quite othen, but turns out they never collaborate because of career and personal reasons, even they are both transparent on details. It also applies to [Pony](https://civitai.com/models/257749?modelVersionId=290640) (non human) / [KOLs from QQ](https://civitai.com/models/9409/or-anything-xl) ([more](https://civitai.com/models/16828?modelVersionId=116468)) which is tricky.

- It is so counter intuitive that datasets / GPU resources are starting to raise, but it comes with profit consideration (no matter business or fame), which further prevent any community collaborations, e.g. [merging](https://civitai.com/models/288584/autismmix-sdxl) or [finetuning](https://civitai.com/models/317902/t-ponynai3) over them. Currently merging Pony models with non-pony models is still a technical challenge.

- Also SDXL has [2 CLIPs](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main) instead of one, making "[train text encoder](https://www.reddit.com/r/StableDiffusion/comments/11haz7m/text_encoder_train_or_not/)" (a setting) become less predictable. Actually author suggest turn if off but mainstream users doesn't agree.

I will continue AstolfoMix XL soon, [after a whole month of building a money pit](https://civitai.com/models/317902/t-ponynai3), along with the frequent update on a [brand new merger](https://github.com/ljleb/sd-mecha) with loads of algorithms (spinoffs from [TIES](https://github.com/ljleb/sd-mecha/blob/main/examples/ties_add_difference.py) / [DARE](https://github.com/ljleb/sd-mecha/blob/main/examples/binomial_dropout_merge.py) / [ModelSoup](https://github.com/ljleb/sd-mecha/blob/main/examples/n_average.py) / [sorry no GitRebasin because no one did it correctly](https://github.com/6DammK9/nai-anime-pure-negative-prompt/blob/main/ch01/rebasin.md) ) and perform in a [long chain of maximum precision](https://github.com/6DammK9/nai-anime-pure-negative-prompt/blob/main/ch05/x45-AstolfoMix-x39te0x39te1-e2e-240222-60d0764.mecha) (still saved as FP16).

BTW I do feel the "[fractal](https://en.wikipedia.org/wiki/Fractal-generating_software)" effect as early as I played SD1.5 on 2022. [UNET](https://en.wikipedia.org/wiki/U-Net) conatins [VGG](https://www.geeksforgeeks.org/vgg-16-cnn-model/) / [prymid](https://en.wikipedia.org/wiki/Pyramid_(image_processing)) structre which can be "[abused](https://github.com/6DammK9/nai-anime-pure-negative-prompt/blob/main/ch01/hires_fix.md)" as global scale **homogeneous** [latent upscaler](https://huggingface.co/stabilityai/sd-x2-latent-upscaler). Warning: Hi-res fix is proposed by A1111 without academic proof. It was supposed to be [other model](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler) like the [refiner of SDXL](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0).
