{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising UNET #\n",
    "\n",
    "### Abstract ###\n",
    "\n",
    "- Self explained. Using `torch_view` as main library.\n",
    "- The docuement below is mainly copied from [mega_cmp.ipynb](./v2a/mmega_cmp.ipynb)\n",
    "\n",
    "### Required libraries ###\n",
    "\n",
    "- ~~Should be the common ML pack we're using. Also with [SD webui's dependency](https://github.com/AUTOMATIC1111/stable-diffusion-webui).~~\n",
    "\n",
    "- [torchview](https://torchview.dev/)\n",
    "- [scikit-learn](https://scikit-learn.org/stable/install.html)\n",
    "- [NetworkX](https://networkx.org/documentation/stable/release/release_3.0.html)\n",
    "- [safetensors](https://huggingface.co/docs/safetensors/index)\n",
    "- [diffusers](https://huggingface.co/docs/diffusers/installation)\n",
    "- [omegaconf](https://anaconda.org/conda-forge/omegaconf)\n",
    "- [pytorch](https://pytorch.org/get-started/locally/#windows-python)\n",
    "- [matplotlib](https://matplotlib.org/stable/api/matplotlib_configuration_api.html)\n",
    "- [numpy](https://numpy.org/)\n",
    "- [torchinfo](https://pypi.org/project/torchinfo/)\n",
    "\n",
    "### Some layer name to interprept (for SD1.5) ###\n",
    "- `first_stage_model`: VAE\n",
    "- `cond_stage_model`: Text Encoder\n",
    "- `model.diffusion_model`: Diffusion model\n",
    "- `model_ema`: EMA model for training\n",
    "- `cumprod`, `betas`, `alphas`: `CosineAnnealingLR`\n",
    "\n",
    "### Some notation (Useful in the bin chart) ###\n",
    "- `attn1`: `sattn` = *Self attention*\n",
    "- `attn2`: `xattn` = *Cross attention*\n",
    "- `ff`: *Feed forward*\n",
    "- `norm`: [Normalisation layer](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html). `elementwise_affine=True` introduces trainable `bias` and `weight`. \n",
    "- `proj`: *Projection*\n",
    "- `emb_layers`: *Embedding layers*\n",
    "- `others`: `ff` + `norm` + `proj` + `emb_layers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'svg'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from safetensors.torch import load_file #safe_open\n",
    "from diffusers import UNet2DConditionModel\n",
    "\n",
    "from torchview import draw_graph\n",
    "from torchinfo import summary\n",
    "\n",
    "import graphviz\n",
    "graphviz.set_jupyter_format('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for OMP: Error #15\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Support 'cuda', but 'cpu' is arleady fast.\n",
    "g_device = \"cuda:0\" #\"cpu\"\n",
    "# Currently for generating graph only.\n",
    "g_seed = 114514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path\n",
    "model_path = {\n",
    "    \"sd1\": \"runwayml/stable-diffusion-v1-5\",\n",
    "    \"sd2\": \"stabilityai/stable-diffusion-2-1\",\n",
    "    \"sdxl\": \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "}\n",
    "\n",
    "model_type = torch.float16 if \"cuda\" in g_device else torch.float # CPU doesn't support FP16 / FP8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only online model is available.\n",
    "\n",
    "`load_single_file` is failed (versioning hell, omitted). I load online model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_instance = None # Clear\n",
    "unet_instance = {} # Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run it later\n",
    "# for k in model_path.keys():\n",
    "#    unet_instance[k] = UNet2DConditionModel.from_pretrained(model_path[k], subfolder=\"unet\",  torch_dtype=torch.float16).to(g_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input size is trial and error.\n",
    "\n",
    "Not actually, we can read `config.json` form the actual official model in HuggingFace. Originally it is scattered in different Git Repos, but HF does a great job here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not Used.\n",
    "input_data_mapping_sample = {\n",
    "    \"sd1\": {\n",
    "        'sample': torch.rand(1280, 4, 8, 8, dtype=model_type).to(g_device),\n",
    "        'timestep': torch.rand(1, dtype=model_type).to(g_device),\n",
    "        'encoder_hidden_states': torch.rand(1280, 77, 768, dtype=model_type).to(g_device),\n",
    "    },\n",
    "    \"sd2\": {\n",
    "        'sample': torch.rand(1280, 4, 20, 20, dtype=model_type).to(g_device),\n",
    "        'timestep': torch.rand(1, dtype=model_type).to(g_device),\n",
    "        'encoder_hidden_states': torch.rand(1280, 77, 1024, dtype=model_type).to(g_device),\n",
    "    },\n",
    "    \"sdxl\": {\n",
    "        'sample': torch.rand(1280, 4, 20, 20, dtype=model_type).to(g_device),\n",
    "        'timestep': torch.rand(1, dtype=model_type).to(g_device),\n",
    "        'encoder_hidden_states': torch.rand(1280, 77, 2048, dtype=model_type).to(g_device),\n",
    "        'added_cond_kwargs': {\n",
    "            'text_embeds': torch.rand(1280, 2560, dtype=model_type).to(g_device),\n",
    "            'time_ids': torch.rand(1280, dtype=model_type).to(g_device),\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Graph output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_paths = {\n",
    "    \"sd1\": \"./sd1_unet\",\n",
    "    \"sd2\": \"./sd2_unet\",\n",
    "    \"sdxl\": \"./sdxl_unet\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop(cur_unet):\n",
    "    unet_instance[cur_unet] = UNet2DConditionModel.from_pretrained(model_path[cur_unet], subfolder=\"unet\",  torch_dtype=model_type).to(g_device) if cur_unet not in unet_instance else unet_instance[cur_unet]\n",
    "\n",
    "    batch = unet_instance[cur_unet].config.block_out_channels[-1]\n",
    "    channel = unet_instance[cur_unet].config.in_channels\n",
    "    sequence_length = 77 # See CLIP\n",
    "    feature_dim = unet_instance[cur_unet].config.cross_attention_dim\n",
    "    attention_head_dim = unet_instance[cur_unet].config.attention_head_dim\n",
    "    height = attention_head_dim if isinstance(attention_head_dim, int) else attention_head_dim[-1]\n",
    "    width = height #square is fine\n",
    "    step = 1 #arbitary single float\n",
    "\n",
    "    inplace_input_data = {\n",
    "        'sample': torch.rand(batch, channel, height, width, dtype=model_type).to(g_device),\n",
    "        'timestep': torch.rand(step, dtype=model_type).to(g_device),\n",
    "        'encoder_hidden_states': torch.rand(batch, sequence_length, feature_dim, dtype=model_type).to(g_device),\n",
    "    }\n",
    "\n",
    "    # SDXL special\n",
    "    if cur_unet == \"sdxl\":\n",
    "        addition_time_embed_dim = unet_instance[cur_unet].config.addition_time_embed_dim\n",
    "        projection_class_embeddings_input_dim = unet_instance[cur_unet].config.projection_class_embeddings_input_dim\n",
    "        time_sequence_length = projection_class_embeddings_input_dim - addition_time_embed_dim\n",
    "        inplace_input_data['added_cond_kwargs'] = {\n",
    "            'text_embeds': torch.rand(batch, time_sequence_length, dtype=model_type).to(g_device),\n",
    "            'time_ids': torch.rand(batch, dtype=model_type).to(g_device),\n",
    "        }\n",
    "\n",
    "    model_summary = summary(unet_instance[cur_unet], \n",
    "        input_data=inplace_input_data, \n",
    "        col_names=(\"input_size\", \"output_size\", \"num_params\")\n",
    "    )\n",
    "\n",
    "    with open(filename_paths[cur_unet] + '.txt', 'w') as the_file:\n",
    "        the_file.write(str(model_summary))\n",
    "\n",
    "    unet_png = draw_graph(unet_instance[cur_unet], \n",
    "        input_data=inplace_input_data, \n",
    "        graph_name=model_path[cur_unet], \n",
    "        device=g_device, mode=\"eval\", \n",
    "        depth=1,       \n",
    "        roll=True,        \n",
    "        save_graph=True,\n",
    "        filename=filename_paths[cur_unet]\n",
    "    ) #, expand_nested=True, hide_inner_tensors=False, \n",
    "\n",
    "    #unet_png.visual_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sd1`: Should run with no problem\n",
    "- `sd2`: May OOM, however I'm using RTX 3090 now.\n",
    "- `sdxl`: This is tricky: No docuement. [Read code](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/unet_2d_condition.py) for workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "\n",
      "(process:21340): Pango-WARNING **: 00:39:33.822: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "\n",
      "(process:31336): Pango-WARNING **: 00:39:52.346: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "\n",
      "(process:23316): Pango-WARNING **: 00:40:34.605: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    }
   ],
   "source": [
    "for k in filename_paths:\n",
    "    main_loop(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all diagrams and summaries are generated. Now we can try to map MBW layers (`IN00-11`, `MID`, `OUT00-11`) to the diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_file(path, device=device)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
